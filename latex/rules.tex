\documentclass[11pt,a4paper]{article}
%twocolumn
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{tikz}
\usepackage[margin=0.5in]{geometry}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{syntax}
\usepackage{lscape}
\usepackage{stmaryrd}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{mathpartir}
%\usepackage{fontspec}
%\usepackage[pdftex]{graphicx}

%\usetikzlibrary{positioning,calc}

\DeclareMathSymbol{\mlq}{\mathord}{operators}{``}
\DeclareMathSymbol{\mrq}{\mathord}{operators}{`'}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\argmax}{\arg\!\max}

%\setmonofont{lmmono8}
%\setmainfont[Mapping=olydis]{Heuristica}
\usepackage{newunicodechar}
\newunicodechar{≠}{=\llap{/}}
\newunicodechar{≔}{:\raisebox{-0.18ex}[\height][\depth]{=}}

\def\extraVskip{3pt}
\newenvironment{scprooftree}[1]%
{\gdef\scalefactor{#1}\begin{center}\proofSkipAmount \leavevmode}%
    {\scalebox{\scalefactor}{\DisplayProof}\proofSkipAmount \end{center} }

\makeatletter
\providecommand{\bigsqcap}{%
    \mathop{%
        \mathpalette\@updown\bigsqcup
    }%
}
\newcommand*{\@updown}[2]{%
    \rotatebox[origin=c]{180}{$\m@th#1#2$}%
}
\makeatother

\setlength{\parindent}{0cm}


%% decoration
\newcommand{\pa}[1]{\ensuremath{{#1}^{\checkmark}}}
\newcommand{\pb}[1]{\ensuremath{{#1}^{\circ}}}

\newcommand{\grad}[1]{\widetilde{#1}}

%% ALIASES
% fonts
\newcommand{\std}{\textrm}
\newcommand{\ttt}{\texttt}
\newcommand{\tset}{\textsc}
\newcommand{\predicate}{\textsf}
% names
\newcommand{\svl}{\std{SVL}\xspace}
\newcommand{\dvl}{\std{DVL}\xspace}
\newcommand{\gvl}{\std{GVL}\xspace}

% sets
\newcommand{\setProgram}{\tset{Program}\xspace}
\newcommand{\setClass}{\tset{Class}\xspace}
\newcommand{\setField}{\tset{Field}\xspace}
\newcommand{\setMethod}{\tset{Method}\xspace}
\newcommand{\setContract}{\tset{Contract}\xspace}
\newcommand{\setType}{\tset{Type}\xspace}
\newcommand{\setStmt}{\tset{Stmt}\xspace}
\newcommand{\setFormula}{\tset{Formula}\xspace}
\newcommand{\setFormulaA}{\tset{SatFormula}\xspace}
\newcommand{\setFormulaB}{\tset{SfrmFormula}\xspace}
\newcommand{\setExpr}{\tset{Expr}\xspace}
\newcommand{\setVal}{\tset{Val}\xspace}
\newcommand{\setVar}{\tset{Var}\xspace}
% expressions
\newcommand{\ev}[1]{\ttt{#1}}
\newcommand{\ex}[1]{\ttt{#1}}
\newcommand{\edot}[2]{\ttt{#1.#2}}
\newcommand{\ethis}{\ex{this}}
\newcommand{\eresult}{\ex{result}}
\newcommand{\enull}{\ttt{null}}
% formulas
\newcommand{\phiCons}[2]{\ttt{#1\:*\:#2}}
\newcommand{\phiFalse}[0]{\ttt{false}}
\newcommand{\phiTrue}[0]{\ttt{true}}
\newcommand{\phiEq}[2]{\ttt{(#1 = #2)}}
\newcommand{\phiNeq}[2]{\ttt{(#1 ≠ #2)}}
\newcommand{\phiAcc}[2]{\ttt{acc(#1.#2)}}
\newcommand{\qm}{\ttt{?}}
\newcommand{\withqm}[1]{\ttt{\qm\:*\:$#1$}}
\newcommand{\withqmGen}[1]{\ttt{$#1$\:\wedge\:\qm}}
% statements
\newcommand{\sFieldAssign}[3]{\ttt{#1.#2 ≔ #3;}}
\newcommand{\sVarAssign}[2]{\ttt{#1 ≔ #2;}}
\newcommand{\sAlloc}[2]{\ttt{#1 ≔ new #2;}}
\newcommand{\sCall}[4]{\ttt{#1 ≔ #2.#3(#4);}}
\newcommand{\sReturn}[1]{\ttt{return #1;}}
\newcommand{\sAssert}[1]{\ttt{assert #1;}}
\newcommand{\sRelease}[1]{\ttt{release #1;}}
\newcommand{\sDeclare}[2]{\ttt{#1~#2;}}
\newcommand{\sHold}[2]{\ttt{hold #1~\{ #2 \};}}
% type
\newcommand{\type}[1]{\ttt{#1}}
\newcommand{\Tint}{\type{int}}
% composite syntax
\newcommand{\class}[3]{\ttt{class {#1}~\{ {#2} {#3} \}}}
\newcommand{\method}[6]{\ttt{{#1}~{#2}({#3}~{#4})~{#5}~\{ {#6} \}}}
\newcommand{\contract}[2]{\ttt{requires {#1}; ensures {#2};}}
\newcommand{\field}[2]{\ttt{{#1}~{#2};}}
%% predicates
% well-formed
\newcommand{\OK}{~\predicate{OK}}
\newcommand{\OKinC}{~\predicate{OK in}~C}
% framing
\newcommand{\sfrme}{\ensuremath{\vdash_\texttt{frm}}\,}
\newcommand{\sfrmphi}{\ensuremath{\vdash_\texttt{sfrm}}\,}
% evaluation
\newcommand{\evalex}[4]{#1,#2 \vdash #3 \Downarrow #4}
\newcommand{\evale}[2]{H,\rho \vdash #1 \Downarrow #2}
\newcommand{\evalphix}[4]{#1,#2,#3 \vDash #4}
\newcommand{\evalphi}{\evalphix H \rho A}
% extraction
\newcommand{\fieldType}{\predicate{fieldType$_p$}}
\newcommand{\fields}{\predicate{fields$_p$}}
\newcommand{\mpre}{\predicate{mpre$_p$}}
\newcommand{\mpost}{\predicate{mpost$_p$}}
\newcommand{\mmethod}{\predicate{method$_p$}}
% other
\newcommand{\dom}{\predicate{dom}}
\newcommand{\writesTo}{\predicate{writesTo}}
\newcommand{\sType}[3]{{#1} \vdash {#2} : {#3}}
\newcommand{\defaultValue}[1]{\predicate{defaultValue(#1)}}
\newcommand{\defeq}{\overset{\predicate{def}}{=}}
\newcommand{\accFor}[1]{\llbracket #1 \rrbracket}
% footprint
\newcommand\floor[1]{\lfloor#1\rfloor}
\newcommand\ceil[1]{\lceil#1\rceil}
\newcommand{\staticFP}[1]{\ensuremath{\floor{#1}}}
\newcommand{\dynamicFP}[3]{\ensuremath{\floor{#3}_{#1,#2}}}
% static sem
\newcommand{\thoare}[4]{{#1} \vdash \{{#2}\} {#3} \{{#4}\}}
\newcommand{\funHoare}{\mathcal{H}}
\newcommand{\funHoareA}{\mathcal{F}}
\newcommand{\funHoareApred}{\mathcal{P}}
\newcommand{\funHoareB}{\mathcal{I}}
\newcommand{\funHoareBimp}{\mathcal{J}}
\newcommand{\funHoareC}{\mathcal{M}}
% dyn sem
\newcommand{\sstepGeneric}[5]{({#1}, {#2}) \rightarrow^{#3} ({#4}, {#5})}
\newcommand{\sstep}[4]{\sstepGeneric {#1} {#2} {} {#3} {#4}}
\newcommand{\ssteps}[4]{\sstepGeneric {#1} {#2} * {#3} {#4}}


% OLD:

\newcommand{\hasTypePremise}[3]{[#1 : #2]_{#3}}
\newcommand{\hasTypeFormula}[3]{{\llbracket #1 : #2\rrbracket}_{#3}}

\newcommand{\Heap}{H}

%DEPRECATED
\newcommand{\true}{\ensuremath{\texttt{true}}}
\newcommand{\vnull}{\ensuremath{\texttt{null}}}
\newcommand{\xresult}{\ensuremath{\texttt{result}}}
\newcommand{\xthis}{\ensuremath{\texttt{this}}}
\newcommand{\new}{\ensuremath{\texttt{new}~}}
\newcommand{\assert}{\ensuremath{\texttt{assert}~}}
\newcommand{\release}{\ensuremath{\texttt{release}~}}
\newcommand{\return}{\ensuremath{\texttt{return}~}}
\newcommand{\acc}{\ensuremath{\texttt{acc}}}
%DEPRECATED


%\newcommand{\staticFP}[1]{\ensuremath{\texttt{static-footprint}(#1)}}
%\newcommand{\dynamicFP}[3]{\ensuremath{\texttt{footprint}_{#1,#2}(#3)}}

\newcommand{\rlabel}[1]{\RightLabel{\quad #1}}

\newcommand{\requires}{\ensuremath{\texttt{requires}~}}
\newcommand{\ensures}{\ensuremath{\texttt{ensures}~}}


\newcommand{\hoare}[3]{\vdash\{#1\}#2\{#3\}}
\newcommand{\ghoare}[3]{\grad{\vdash}\{#1\}#2\{#3\}}

\newcommand{\hsc}{~\hat{*}~}
\newcommand{\gsc}{~\grad{*}~}
\newcommand{\wo}[2]{#1\textbf{[w/o~}#2\textbf{]}} 
\newcommand{\imp}{\textrm{imp}}

\newcommand{\goal}{\ensuremath{\textrm{goal}_{\Gamma}}}
\newcommand{\TappVER}{\ensuremath{\textrm{TappVER}}}
\newcommand{\GTappVER}{\ensuremath{\grad{\textrm{T}}\textrm{appVER}}}

% dyn
\newcommand{\valphi}[1]{\llbracket #1 \rrbracket}

\newcommand{\dType}[4]{#1, #2 \vdash #3 : #4}

\newcommand{\Tfs}{\overline{T}~\overline{f}}


\begin{document}
\pagenumbering{arabic}

\section{Formula Syntax}
%% reasonable: formulas evaluable at runtime
Checking a formula at runtime, i.e. performing a runtime assertion check, is the integral part of dynamic verification and thus plays a role in gradual verification.
Formally, a runtime assertion check corresponds to evaluating a closed formula since the environment provides an instantiation of the formula's free variables.
It is reasonable to demand that this check can be performed in a time polynomial, if not linear to the formula's length (the specifics are up to the language designer, of course).

%% impact on formula syntax: quantification
Such a requirement effectively restricts the formula syntax.
For example, a syntax containing universal quantification generally violates above runtime limitations:
A formula $\forall x_1 \in M, x_2 \in M, ..., x_n \in M. P(x_1, x_2, ..., x_n)$ would require $|M|^n$ steps to evaluate.
As a result, the execution time is already exponential if $M$ is finite -- and unbounded otherwise.

%% impact on formula syntax: still pretty little restriction
Putting quantification (and therefore the introduction of new variables) aside, there are little restrictions to formula syntax, essentially allowing any predicates or operations that can be evaluated in linear/polynomial time.
This includes equality/inequality relations, arithmetic and even own predicates that might be recursive to some extent.

%% nevertheless: static verification undec.
Nevertheless such “easily” evaluable formulas are also subject to higher order reasoning in the static verification rules, including checks like satisfiability of or implication between formulas.
Those judgments basically introduce quantification of the free variables, whereas evaluation works on a concrete instantiation.
This makes static verification NP-hard in general:
\begin{description}
    \item[NPC] One can easily encode SAT instances as formulas, either directly (if the syntax covers boolean variables, conjunction and disjunction) or using arithmetic (if the syntax covers addition and a comparison relation like “greater-than”). Note that although evaluating such formulas is trivial, checking for satisfiability is NP-complete. % TODO: reference???
    \item[Undecidability] ...Paeno-arithmetic % TODO
\end{description}

%% our syntax
We chose the formula syntax of ... specifically to ensure that even static semantics are decidable in polynomial time.
This allowed applying the procedures of AGT directly, as they are based on a decidable type system, i.e. decidable .

\subsection{Impact of NP-hard Verification Predicates}
Let's assume that our rules for static verification indeed contain an NP-hard predicate $P$. (NOTE: need positive occurrence for following reasoning!)
The immediate consequence is that any working verifier would have to realize a conservative approximation of the actual predicate.

Under-approximation: for static guarantees to hold, verifier must under-approximate $P$... blabla

Over-approximation: for (det.) gradual lifting to be ?sound?, it must over-approximate $P$... blabla


\section{Lifting, revised}
Given binary predicate $P$.
\subsection{Predicate Lifting}
\begin{displaymath}
\grad{P}(\grad{a}, \grad{b}) 
\quad\iff\quad
\exists a \in \gamma(\grad{a}), b \in \gamma(\grad{b}). P(a, b)
\quad\iff\quad
(\gamma(\grad{a}) \times \gamma(\grad{b})) \cap P \neq \emptyset
\end{displaymath}

\begin{description}
    \item[“$\Leftarrow$”/Soundness]~\\
    Required for gradual guarantee.
    Gradualization (of predicate or arguments) cannot “unsatisfy” the predicate.
    
    \item[“$\Rightarrow$”/Optimality]~\\
    Not required but desirable. Guarantees that there is a chance of satisfying the original predicate.
\end{description}

\subsection{Functions}
\begin{displaymath}
\exists (a, b) \in P. a \in \gamma(\grad{a})
\quad\implies\quad
\vec{P}(\grad{a}) = \grad{b}
\quad\implies\quad
\forall (a, b) \in P. a \in \gamma(\grad{a}) \implies b \in \gamma(\grad{b})
\end{displaymath}

\begin{align*}
&\exists a, b. P(a, b) \\
\quad\implies\quad
&\forall \grad{a}. \exists a \in \gamma(\grad{a}), b. P(a, b) \\
\quad\implies\quad
&\forall \grad{a}. \exists a \in \gamma(\grad{a}), b \in \gamma(\vec{P}(\grad{a})). P(a, b) \\
\quad\implies\quad
&\forall \grad{a}. \grad{P}(\grad{a}, \vec{P}(\grad{a})) \\
\end{align*} 


\section{Syntax}%%
\input{../../GradVerThesis/data/svl-syntax}

\begin{align*}	  
\\ &H			&&\in~~ (o \rightharpoonup (C,\overline{(f \rightharpoonup v)}))
\\ &\rho		&&\in~~ (x \rightharpoonup v)
\\ &\Gamma		&&\in~~ (x \rightharpoonup T)
\\ &A_s			&&::= \overline{(e, f)}
\\ &A_d			&&::= \overline{(o, f)}
\\ &S			&&::= (\rho, A_d, \overline{s}) \cdot S ~|~ nil
\end{align*}

\section{Assumptions}%%
All the rules in the following sections are implicitly parameterized over a $program p$ that is well-formed.

\section{Static semantics}

\subsection{Expressions ($A_s \sfrme e$)}
\input{../../GradVerThesis/data/autogen/staticExpression}

\subsection{Formulas ($A_s \sfrmphi \phi$)}
\input{../../GradVerThesis/data/autogen/staticFormula}

\begin{mathpar}
\inferrule* [Right=WFSepOp]
{
A_s \sfrmphi \phi_1 \\ 
A_s \cup \staticFP {\phi_1} \sfrmphi \phi_2
}
{A_s \sfrmphi \phi_1 * \phi_2}
\end{mathpar}

\subsection{Footprint ($\staticFP {\phi} = A_s$)}
\input{../../GradVerThesis/data/svl-sem-stat-fp}

\subsection{Type ($\sType {\Gamma} {e} {T}$)}
\input{../../GradVerThesis/data/autogen/staticTypeExpression}

\subsection{Hoare ($\Gamma \hoare {\phi} {\overline s} {\phi}$)}
\input{../../GradVerThesis/data/autogen/staticSemantics}

%\subsubsection{Notation}
%\input{staticSemanticsNotation}

\subsubsection{Deterministic}
\input{staticSemanticsDeterm}

\subsubsection{Gradual}
\input{staticSemanticsDetermGrad}

\section{Dynamic semantics}
\subsection{Expressions ($\evale {e} {v}$)}
\input{../../GradVerThesis/data/svl-sem-dyn-expr}

\subsection{Formulas ($\evalphi \phi$)}
\input{../../GradVerThesis/data/autogen/dynamicFormula}

We give a denotational semantics of formulas as $\valphi {\phi} = \{~ (H,\rho,A) ~|~ \evalphi {\phi} ~\}$

Note: $\phi \text{ satisfiable} \iff \valphi {\phi} \neq \emptyset$

\subsubsection{Implication ($\phi_1 \implies \phi_2$)}
%\begin{equation*}
%\phi_1 \implies \phi_2
%\quad\quad \iff \quad\quad
%\valphi {\phi_1} \subseteq \valphi {\phi_2}
%\end{equation*}

\begin{equation*}
\phi_1 \implies \phi_2
\quad\quad \iff \quad\quad
\forall H, \rho, A: \evalphi \phi_1 \implies \evalphi \phi_2
\end{equation*}
Drawn from def. of entailment in ``A Formal Semantics for Isorecursive and Equirecursive State Abstractions''.

\subsubsection{Implying inequality}
\begin{align*}
\\   & \phi * (e_1 = e_1) * (e_2 = e_2) \implies (e_1 \neq e_2)
\\ =~& \forall H, \rho, A:~ \evalphi \phi * (e_1 = e_1) * (e_2 = e_2) \implies \evalphi (e_1 \neq e_2)
\\ =~& \forall H, \rho, A:~  (\exists v_1, v_2:~ \evale {e_1} {v_1} \wedge \evale {e_2} {v_2} \wedge \evalphi \phi) \implies (\exists v_1, v_2:~ \evale {e_1} {v_1} \wedge \evale {e_2} {v_2} \wedge (v_1 \neq v2))
\\ =~& \forall H, \rho, A, v_1, v_2:~  (\evale {e_1} {v_1} \wedge \evale {e_2} {v_2} \wedge \evalphi \phi) \implies (\exists v_1, v_2:~ \evale {e_1} {v_1} \wedge \evale {e_2} {v_2} \wedge (v_1 \neq v2))
\\ =~& \forall H, \rho, A, v_1, v_2:~  (\evale {e_1} {v_1} \wedge \evale {e_2} {v_2} \wedge \evalphi \phi) \implies (v_1 \neq v2)
\\ =~& \forall H, \rho, A, v_1, v_2:~  \neg (\evale {e_1} {v_1} \wedge \evale {e_2} {v_2} \wedge \evalphi \phi) \vee (v_1 \neq v2)
\\ =~& \forall H, \rho, A, v_1, v_2:~  \neg (\evale {e_1} {v_1} \wedge \evale {e_2} {v_2} \wedge \evalphi \phi \wedge (v_1 = v2))
\\ =~& \forall H, \rho, A:~ \neg (\exists v_1, v_2:~ \evale {e_1} {v_1} \wedge \evale {e_2} {v_2} \wedge \evalphi \phi \wedge (v_1 = v2))
\\ =~& \forall H, \rho, A:~ \neg (\evalphi \phi \wedge \evalphi (e_1 = e_2))
\\ =~& \forall H, \rho, A:~ \neg \evalphi \phi * (e_1 = e_2)
\\ =~& \neg \text{sat~}(\phi * (e_1 = e_2))
\end{align*}

\subsection{Footprint ($\dynamicFP {H} {\rho} {\phi} = A_d$)}
\input{../../GradVerThesis/data/svl-sem-dyn-fp}

\subsection{Small-step ($\sstep H S H S$)}
\input{dynamicSemantics}

\section{Gradualization}
\subsection{Syntax}
\subsubsection{Gradual formula}
\begin{align*}
&\grad{\phi} \quad ::= \quad \phi ~|~ \withqm{\phi}
\end{align*}

Note: consider $?$ in other positions as ``self-framing delimiter'', but with semantically identical meaning.

As long as $?$ is only legal in the front though: $\phi_1 * \grad{\phi_2}$ propagates the $?$ to the very left in case $\grad{\phi_2}$ contains one.

\subsubsection{Self-framed and satisfiable formula}
\begin{align*}
&\hat{\phi} \quad \in \quad \{~ \phi ~|~ \sfrmphi \phi \wedge \text{sat~} \phi ~\}
\end{align*}

\subsection{Concretization}
\begin{align*}
&\gamma(\hat{\phi}) ~&&= \{~ \hat{\phi} ~\} \\
&\gamma(?\:*\:\phi') ~&&= \{~ \hat{\phi} ~|~ \hat{\phi} \implies \phi' ~\} \text{~~if $\phi'$ satisfiable} \\
&\gamma(\phi) \text{ undefined otherwise} \\
~\\
&\grad{\phi_1} \sqsubseteq \grad{\phi_2} \quad:\iff\quad \gamma(\grad{\phi_1}) \subseteq \gamma(\grad{\phi_2})
\text{useful extension:}\\
&\bot \sqsubseteq \bot
\end{align*}

\newcommand{\dalpha}{\dot{\alpha}}

\subsection{Abstraction}
\begin{align*}
&\alpha(\overline{\phi}) &&= \min_{\sqsubseteq} {\{~ \grad{\phi} ~|~ \overline{\phi} \subseteq \gamma(\grad{\phi}) ~\}}\\
\end{align*}
Equivalent to:
\begin{align*}
&\alpha(\{ \phi \}) &&= \phi\\
&\alpha(\overline{\phi}) &&= \dalpha(\overline{\phi}) := \sup_{\sqsubseteq} {\{~ \withqm{\phi} ~|~ \phi \in \overline{\phi} ~\}}\\
\end{align*}

Proved:
\begin{itemize}
	\item partial function
	\item sound
	\item optimal
	\item $\alpha(\gamma(\grad{\phi})) = \grad{\phi}$
    \item does this make $\langle \gamma, \alpha \rangle$ a (partial) “galois insertion”?
\end{itemize}

\subsection{Temp}
$\dagger$:
$$(\phi_1 \implies \phi_2) \implies f(\phi_1) \text{ defined} \implies f(\phi_2) \text{ defined}$$
\begin{itemize}
	\item Concat: the case (total in usage!)
	\item remove variable/access: total
	\item substitution: total
	\item implication: NOT the case
\end{itemize}
The gradual Hoare rules (except GHSec) themselves are total apart from implication part!

~\\
Functions must preserve satisfiability and self-framing!


\subsection{Lifting functions}
Gradual lifting $\grad{f} : \grad{\phi} \rightarrow \grad{\phi}$ of a function $f : \phi \rightarrow \phi$:
$$\grad{f}(\grad{\phi}) := \alpha(\overline{f}(\gamma(\grad{\phi})))$$ 

This formal definition has drawbacks:
\begin{itemize}
    \item Calculations on infinite set (not implementable)
    \item Determine supremum of infinite set (not even clear if it exists)
\end{itemize}

Turns out above definition can be rewritten in an equivalent, computable way.

\subsubsection{Dominator Theory}
TODO: first tackle singleton case etc.

Theorem:\\
% $\gamma(\phi) = \biguplus_{i = 1..n} \gamma(\hat{\phi}_i)$
For every $\phi$, there exists a finite set of “dominators” $\dom(\phi)$, such that 
$$\gamma(\withqm{\phi}) = \bigcup_{\hat{\phi} \in \dom(\phi)} \gamma(\withqm{\hat{\phi}})$$
~\\

Consequence: 
\begin{align*}
\withqm{\phi} 
&= \alpha(\gamma(\withqm{\phi})) \\
&= \dalpha(\gamma(\withqm{\phi})) \\
&= \dalpha(\bigcup_{\hat{\phi} \in \dom(\phi)} \gamma(\withqm{\hat{\phi}})) \\
&= \dalpha(\bigcup_{\hat{\phi} \in \dom(\phi)} \{ \hat{\phi} \}) \\
&= \dalpha(\dom(\phi)) \\
&= \sup_{\sqsubseteq} {\{~ \withqm{\phi'} ~|~ \phi' \in \dom(\phi) ~\}}
\end{align*}
~\\
Analogous, for monotonic $f$: 
\begin{align*}
&~~~~ \alpha(\overline{f}(\gamma(\withqm{\phi}))) \\
&\overset{f \text{ not narrowing to single element (also includes definedness!)}}{=} \dalpha(\overline{f}(\gamma(\withqm{\phi}))) \\
&= \dalpha(\overline{f}(\bigcup_{\hat{\phi} \in \dom(\phi)} \gamma(\withqm{\hat{\phi}}))) \\
&\overset{\dagger}{=} \dalpha(\overline{f}(\bigcup_{\hat{\phi} \in \dom(\phi)} \{ \hat{\phi} \})) \\
&= \dalpha(\overline{f}(\dom(\phi))) \\
&= \sup_{\sqsubseteq} {\{~ \withqm{f(\phi')} ~|~ \phi' \in \dom(\phi) ~\}}
\end{align*}

~\\
Re-definition of gradual lifting:
$$\grad{f}(\phi) := f(\phi)$$ 
$$\grad{f}(\withqm{\phi}) := \alpha(\overline{f}(\gamma(\withqm{\phi}))) = \dalpha(\overline{f}(\dom(\phi)))$$ 

In terms of implementation: At least no more infinite sets, need to calculating supremum remains.\\

Interesting observation:
$$\grad{f}(\withqm{\hat{\phi}}) = \dalpha(\overline{f}(\dom(\hat{\phi}))) = \dalpha(\overline{f}(\{ \hat{\phi} \})) = \dalpha(\{ f(\hat{\phi}) \}) = \,\,\withqm{f(\hat{\phi})}$$

This observation raises the question whether it is possible to generalize the equality to work with arbitrary formulas, getting rid of $\dalpha$ and calculating a supremum entirely.

%Further observations:

%~\\
%Lemmas:
%\begin{itemize}
%    \item $\dom(\phi) \subseteq \gamma(\withqm{\phi})$
%    \item $\max \gamma(\withqm{\hat{\phi}}) = \hat{\phi}$
%    \item $f : \phi \rightarrow \phi \text{ monotonic }  \implies  \max \overline{\phi} = \phi'  \implies  \max \overline{f(\phi)} = f(\phi')$
%    \item $\max \overline{\phi} = \phi'  \implies  \alpha(\overline{\phi}) \in \{ \withqm{\phi'}, \phi' \}$
%\end{itemize}

%~\\
%Also:\\
%$\alpha(\overline{f}(\gamma(\phi))) =\, f(\phi)$

\subsubsection{Generalization: Auto-liftable functions}
Goal:
Get a definition of $\grad{f}$ that is even easier to handle and implement.
Therefore we want to investigate whether, or under which circumstances 
$$\grad{f}(\grad{\phi}) = f(\grad{\phi}) \quad\quad\text{(i.e. $f$ applied to the static part of $\grad{\phi}$)}$$
holds.

We call functions $f$ satisfying above equality “auto-liftable”.

% always holds for singletons

Counterexamples:
\begin{itemize}
\item $f(\phi) = \phiCons{\phiAcc {x} {f}}{$\phi$}$ \\
    \begin{equation*}
    \grad{f}(\withqm{\phiEq{\edot{x}{f}}{3}}) = \withqm{\phiFalse} 
    ~\neq~
    \withqm{\phiCons{\phiAcc {x} {f}} {\phiEq{\edot{x}{f}}{3}}} = f(\withqm{\phiEq{\edot{x}{f}}{3}})
    \end{equation*}
    Cause: $\gamma(\withqm{\phiEq{\edot{x}{f}}{3}})$ only contains self-framed formulas, so access to $x.f$ is always included. Adding it another time results in duplicate access and therefore unsatisfiable formulas.
\item $f(\phi) = $ remove all terms containing $\ttt{x}$ \\
    \begin{equation*}
    \grad{f}(\withqm{\phiEq{a}{3}}) = \qm 
    ~\neq~
    \withqm{\phiEq{a}{3}} = f(\withqm{\phiEq{a}{3}})
    \end{equation*}
    Cause: $\phiCons{\phiEq{a}{x}}{\phiEq{x}{3}} \in \gamma(\withqm{\phiEq{a}{3}})$ and $f(\phiCons{\phiEq{a}{x}}{\phiEq{x}{3}}) = \phiTrue$.
    Abstracting from a (non-singleton) set that contains $\phiTrue$ yields $\qm$.
\end{itemize}

~\\
Required: $\alpha(\overline{f}(\gamma(\withqm{\phi}))) =\, \withqm{f(\phi)}$
Note: 

\begin{align*}
\forall \phi' \in \gamma(\withqm{f(\phi)}), \exists \phi'' \in \gamma(\withqm{\phi}), \phi' &\in \gamma(\withqm{f(\phi'')}) \\
\implies \\
\forall \phi' \in \gamma(\withqm{f(\phi)}), \exists \phi'' \in \gamma(\withqm{\phi}), \withqm{\phi'} &\sqsubseteq \,\,\withqm{f(\phi'')} \\
\implies \\
\forall \phi' \in \dom(f(\phi)), \exists \phi'' \in \dom(\phi), \withqm{\phi'} &\sqsubseteq \,\,\withqm{f(\phi'')} \\
\implies \\
\forall \phi' \in \dom(f(\phi)), \withqm{\phi'} &\sqsubseteq \sup_{\sqsubseteq} {\{~ \withqm{f(\phi')} ~|~ \phi' \in \dom(\phi) ~\}} \\
\iff \\
\sup_{\sqsubseteq} {\{~ \withqm{\phi'} ~|~ \phi' \in \dom(f(\phi)) ~\}} &\sqsubseteq \sup_{\sqsubseteq} {\{~ \withqm{f(\phi')} ~|~ \phi' \in \dom(\phi) ~\}} \\
\iff \\
\withqm{f(\phi)}  &\sqsubseteq \alpha(\overline{f}(\gamma(\withqm{\phi})))
\end{align*}

\begin{align*}
\withqm{f(\phi)} &\sqsubseteq \,\,\withqm{f(\phi)} \\
\overset{\dagger}{\implies} \\
\forall \phi' \in \dom(\phi), \withqm{f(\phi')} &\sqsubseteq \,\,\withqm{f(\phi)} \\
\iff \\
\sup_{\sqsubseteq} {\{~ \withqm{f(\phi')} ~|~ \phi' \in \dom(\phi) ~\}} &\sqsubseteq \,\,\withqm{f(\phi)} \\
\overset{\dagger}{\iff} \\
\alpha(\overline{f}(\gamma(\withqm{\phi}))) &\sqsubseteq \,\,\withqm{f(\phi)}
\end{align*}

For a function $f$ to be auto-liftable, the following properties are sufficient:
\begin{itemize}
    \item Monotonicity
    \item $\forall \phi' \in \gamma(\withqm{f(\phi)}), \exists \phi'' \in \gamma(\withqm{\phi}), \phi' \in \gamma(\withqm{f(\phi'')})$ 
    \item $\dagger$
\end{itemize}

\subsubsection{Auto-liftable composition}
Given auto-liftable functions $f$ and $g$, is $g \circ f$ auto-liftable?
Monotonicity is obviously preserved.

Other condition:
\begin{align*}
\withqm{g(f(\phi))} \sqsubseteq \alpha(\overline{g}(\gamma(\withqm{f(\phi)}))) &\,\wedge
\,\,\withqm{f(\phi)} \sqsubseteq \alpha(\overline{f}(\gamma(\withqm{\phi}))) \\
\implies \\
\withqm{g(f(\phi))} \sqsubseteq \alpha(\overline{g}(\gamma(\withqm{f(\phi)}))) &\wedge
\alpha(\gamma(\withqm{f(\phi)})) \sqsubseteq \alpha(\overline{f}(\gamma(\withqm{\phi}))) \\
\implies \\
\withqm{g(f(\phi))} \sqsubseteq \alpha(\overline{g}(\gamma(\withqm{f(\phi)}))) &\wedge
\alpha(\overline{g}(\gamma(\withqm{f(\phi)}))) \sqsubseteq \alpha(\overline{g}(\overline{f}(\gamma(\withqm{\phi})))) \\
\implies \\
\withqm{g(f(\phi))} &\sqsubseteq \alpha(\overline{g}(\overline{f}(\gamma(\withqm{\phi})))) \\
\implies \\
\withqm{(g \circ f)(\phi)} &\sqsubseteq \alpha(\overline{(g \circ f)}(\gamma(\withqm{\phi}))) \\
\end{align*}


%\subsection{$(\phi, \implies)$ is semilattice}
%According to the definition of $\implies$ via $\subseteq$, we define
%\begin{align*}
%\phi_a \sqcap \phi_b = \phi_c   \quad :\iff \quad   \valphi{\phi_a} \cap \valphi{\phi_b} = \valphi{\phi_c}
%\end{align*}

%The question is, whether such $\phi_c$ always exists.



%\subsection{Concretization D (as in denotational)}
%\begin{align*}
%&\gamma(\phi) ~&&= \{~ \valphi{\phi} ~\} \\
%&\gamma(\withqm{\phi}) ~&&= \{~ \valphi{\phi\:*\:\phi_x} ~|~ \exists \phi_x : \valphi{\phi\:*\:\phi_x} \neq \emptyset ~\} \\
%& ~&&= \{~ \valphi{\phi'} ~|~ \exists \phi' : \emptyset \neq \valphi{\phi'} \wedge \phi' \implies \phi ~\} \\
%& ~&&= \{~ \valphi{\phi'} ~|~ \exists \phi' : \emptyset \neq \valphi{\phi'} \wedge \valphi{\phi'} \subseteq \valphi{\phi} ~\} \\
%\end{align*}

\subsubsection{No liftable composition for HSec - emerging runtime semantics}
Motivation: While compositional lifting (involving $\cdot \gsc \phi$, $\wo {~} {x}$ etc.) works out great in most static Hoare rules, it does not work in HSec.
This is due to a subtlety ($\dagger$)... TODO

% EXAMPLE
\newcommand{\phiSample}{\withqm{\phiNeq{x}{\vnull}}}
\newcommand{\phiSampleX}{\withqm{\phiEq{x.f}{x.f}}}
\newcommand{\sSample}{\sRelease{\phiAcc{x}{f}}}
Example:
\sSample~\sSample
\begin{itemize}
	\item not typable with any static precondition
	\item typable with gradual precondition:
	
	\begin{mathpar}
		\inferrule* [Right=GHRelease]
		{\grad{\imp}(\phiAcc{x}{f})(\phiSample) = \phiSampleX\\
			{\wo {(\phiSampleX)} {\phiAcc{x}{f}}} = \phiSample}
		{\Gamma~ \ghoare {\phiSample} {\sSample} {\phiSample}}
	\end{mathpar}
	\begin{mathpar}
		\inferrule* [Right=GHSec]
		{
			\Gamma~ \ghoare {\phiSample} {\sSample} {\phiSample}\\
			\Gamma~ \ghoare {\phiSample} {\sSample} {\phiSample}
		}
		{\Gamma~ \ghoare {\phiSample} {\sSample~\sSample} {\phiSample}}
	\end{mathpar}
\end{itemize}

Trying to “fix” GHSec statically turns out to be impossible without runtime information. That moves our focus towards dynamic semantics. 

Discussion, comparison with AGT:
\begin{description}
	\item [AGT]~\\
	reduction = composite terms (parts had explicit type annotations!) get simplified to single term.
	
	For type derivations this means that stuff must still be compatible, i.e. the single term must still be typeable.
	The constructor for composite terms ($\grad{\text{T}}$App predicate) is thus not the gradual lifting of TApp - it allows constructing terms which cannot succeed at runtime.
	
	\item [GVER]~\\
	reduction = pushing an environment through, instruction by instruction (analogous to \ttt{ins1(ins2(ins3(env)))} in $\lambda$/AGT-setting).
	
	In other words: Instructions are \textit{not} combined with others to form “simpler” instructions.
	The behavior becomes more apparent if we imagined loops as being part of our language.
	Although HSec is like a counterpart of TApp in constructing composite terms, the dynamic semantics are quite orthogonal.
	HSec semantically would more closely correspond to a dedicated B-combinator - which would then also not provide runtime semantics for AGT.
	
	The fundamental difference is that AGT is based typing terms, giving rules to construct these terms, whereas GVER is based on typing environments, giving rules to construct functions \textit{manipulating} these environments.
	
	Let's pretend we had instead given rules of constructing environments (i.e. environments as values, instructions as functions on these values) and see how to derive \textit{direct} runtime semantics from that.
	In this setting, there would have to be a rule analogous to Tapp:
	\begin{mathpar}
		\inferrule* [Right=\TappVER]
		{
			\Gamma \vdash s : \hat{\phi_{pre}} \rightarrow \hat{\phi_{post}}\\
			\vdash env : \hat{\phi}\\
			\hat{\phi} <: \hat{\phi_{pre}}
		}
		{ \vdash s(env) : \hat{\phi_{post}} }
	\end{mathpar}
	Leveraging our syntax:
	\begin{mathpar}
		\inferrule* [Right=\TappVER]
		{
			\Gamma \hoare {\hat{\phi_{pre}}} {s} {\hat{\phi_{post}}}\\
			env \vdash \hat{\phi}\\
			\hat{\phi} \implies \hat{\phi_{pre}}
		}
		{ s(env) \vdash \hat{\phi_{post}}}
	\end{mathpar}
	Which by definition of implication is exactly the same as:
	\begin{mathpar}
		\inferrule* [Right=\TappVER]
		{
			\Gamma \hoare {\hat{\phi_{pre}}} {s} {\hat{\phi_{post}}}\\
			env \vdash \hat{\phi_{pre}}
		}
		{ s(env) \vdash \hat{\phi_{post}}}
	\end{mathpar}
	Note that this is precisely the definition of soundness, ensuring progress ($s(env)$ being defined) and preservation ($\phi_{post}$ really holding for the new environment).
	Gradual attempt:
	\newcommand{\gdash}{~\grad{\vdash}~}
	\begin{mathpar}
		\inferrule* [Right=\GTappVER]
		{
			\Gamma~ \ghoare {\grad{\phi_{pre}}} {s} {\grad{\phi_{post}}}\\
			env \gdash \grad{\phi_{pre}}
		}
		{ s(env) \vdash \grad{\phi_{post}} }
	\end{mathpar}
	Remark: $env \gdash \grad{\phi_{pre}}$ has a very simple implementation.
	
	Just as it is the case with $\grad{\text{T}}$app, this rule is imprecise, requiring additional measures to make guarantees about runtime behavior: The gradual Hoare premise might require a concretization of $\grad{\phi_{pre}}$ that does not evaluate in $env$. 
	% TODO: example (something with access?)
	
	Unfortunately, the gradual Hoare predicate is not transparent about its requirements for $\grad{\phi_{pre}}$.
	Let's taking a step back and look at the regular Hoare rules:
	They are partial functions, being undefined only if $s$ itself is malformed (you could split that part of the static semantics apart from everything involving $\phi$!) or if the precondition violates some implication.
	
	Now, the gradual Hoare rule guarantees the well-formedness of $s$ itself since the gradualization only affects formulas.
	The critical part is the implication, which is getting weakened by the gradualization, subsequently resulting in $\grad{\text{T}}$appVER being imprecise as illustrated above.
	
	Let's reiterate TappVER, trying to track the precondition requirements explicitly:
	\begin{mathpar}
		\inferrule* [Right=\TappVER]
		{
			\Gamma \hoare {\hat{\phi_{pre}}} {s} {\hat{\phi_{post}}}\\
			\hat{\phi_{pre}} \implies \goal(s)\\
			env \vdash \hat{\phi_{pre}}
		}
		{ s(env) \vdash \hat{\phi_{post}}}
	\end{mathpar}
	...where $\text{goal}(s)$ is supposed to be implied by $\phi_{pre}$ according to the Hoare rule for statement $s$
	(for Hoare rules that don't have such requirement, we define $\text{goal}(s) = \true$).
	
	This can be rewritten as:
	\begin{mathpar}
		\inferrule* [Right=\TappVER]
		{
			\Gamma \hoare {\hat{\phi_{pre}}} {s} {\hat{\phi_{post}}}\\
			env \vdash \goal(s)\\
			env \vdash \hat{\phi_{pre}}
		}
		{ s(env) \vdash \hat{\phi_{post}}}
	\end{mathpar}
	New gradual attempt:
	\begin{mathpar}
		\inferrule* [Right=$\grad{\text{T}}$appVER]
		{
			\Gamma~ \ghoare {\grad{\phi_{pre}}} {s} {\grad{\phi_{post}}}\\
			env \gdash \withqm{\goal(s)}\\
			env \gdash \grad{\phi_{pre}}
		}
		{ s(env) \vdash \grad{\phi_{post}} }
	\end{mathpar}
	This time, the lifting is actually precise.
	Proof:
	% Note: not as lifted function, since $env \vdash \hat{\phi_{pre}}$ actually enforces more precise result than Hoare rule!!!
	\begin{align*}
	&\GTappVER_{\Gamma, s, env}(\grad{\phi_{pre}}, \grad{\phi_{post}})\\
&\implies\\
	&\Gamma~ \ghoare {\grad{\phi_{pre}}} {s} {\grad{\phi_{post}}} ~\wedge~
	env \gdash \withqm{\goal(s)} ~\wedge~
	env \gdash \grad{\phi_{pre}}\\
&\implies\\
	&\Gamma ~\vdash~ s ~\wedge~\\
	&\grad{H}_{\Gamma, s}(\grad{\phi_{pre}}) = \grad{\phi_{post}} ~\wedge~
	env \gdash \withqm{\goal(s)} ~\wedge~
	env \gdash \grad{\phi_{pre}}\\
&\implies\\
	&\Gamma ~\vdash~ s ~\wedge~\\
	&\grad{H}_{\Gamma, s}(\grad{\phi_{pre}}) = \grad{\phi_{post}} ~\wedge~
	env \gdash \grad{\imp}(\goal(s))(\grad{\phi_{pre}})\\
&\implies\\
	&\Gamma ~\vdash~ s ~\wedge~\\
	&\alpha(\overline{K}_{\Gamma, s}(\gamma(\grad{\imp}(\goal(s))(\grad{\phi_{pre}})))) = \grad{\phi_{post}} ~\wedge~
	env \gdash \grad{\imp}(\goal(s))(\grad{\phi_{pre}})\\
&\implies\\
	&\Gamma ~\vdash~ s ~\wedge~\\
	&\gamma(\alpha(\overline{K}_{\Gamma, s}(\gamma(\grad{\imp}(\goal(s))(\grad{\phi_{pre}}))))) = \gamma(\grad{\phi_{post}}) ~\wedge~
	env \gdash \grad{\imp}(\goal(s))(\grad{\phi_{pre}})\\
&\implies\\
	&\Gamma ~\vdash~ s ~\wedge~\\
	&\gamma(\alpha(\overline{K}_{\Gamma, s}(\gamma(\grad{\imp}(\goal(s))(\grad{\phi_{pre}}))))) = \gamma(\grad{\phi_{post}}) ~\wedge~\\
	\exists \hat{\phi_{pre}} \in \gamma(\grad{\imp}(\goal(s))(\grad{\phi_{pre}})) : ~
	&env \vdash \hat{\phi_{pre}}\\
&\implies\\
	&\Gamma ~\vdash~ s ~\wedge~\\
	&\gamma(\alpha(\overline{K}_{\Gamma, s}(\gamma(\grad{\imp}(\goal(s))(\grad{\phi_{pre}}))))) = \gamma(\grad{\phi_{post}}) ~\wedge~\\
	\exists \hat{\phi_{pre}} \in \gamma(\grad{\imp}(\goal(s))(\grad{\phi_{pre}})) : ~
	&env \vdash \hat{\phi_{pre}} ~\wedge~
	K_{\Gamma, s}(\hat{\phi_{pre}}) \in \overline{K}_{\Gamma, s}(\gamma(\imp(\goal(s))(\grad{\phi_{pre}}))) \\
&\implies\\
	&\Gamma ~\vdash~ s ~\wedge~\\
	\exists \hat{\phi_{pre}} \in \gamma(\grad{\imp}(\goal(s))(\grad{\phi_{pre}})) : ~
	& env \vdash \hat{\phi_{pre}} ~\wedge~
	K_{\Gamma, s}(\hat{\phi_{pre}}) \in \gamma(\grad{\phi_{post}}) \\
&\implies\\ % because \grad{imp} is somewhat precise! \overline{imp} not widened by (\gamma \circ \alpha)
	&\Gamma ~\vdash~ s ~\wedge~\\
	\exists \hat{\phi_{pre}} \in \gamma(\grad{\phi_{pre}}) : ~
	& \hat{\phi_{pre}} \implies \goal(s) ~\wedge~
	env \vdash \hat{\phi_{pre}} ~\wedge~
	K_{\Gamma, s}(\hat{\phi_{pre}}) \in \gamma(\grad{\phi_{post}}) \\
&\implies\\
	&\Gamma ~\vdash~ s ~\wedge~\\
	\exists \hat{\phi_{pre}} \in \gamma(\grad{\phi_{pre}}) : ~
	&H_{\Gamma, s}(\hat{\phi_{pre}}) \in \gamma(\grad{\phi_{post}}) ~\wedge~
	env ~\vdash~ \hat{\phi_{pre}}\\
&\implies\\
	&\Gamma ~\vdash~ s ~\wedge~\\
	\exists \hat{\phi_{pre}} \in \gamma(\grad{\phi_{pre}}), \hat{\phi_{post}} \in \gamma(\grad{\phi_{post}}) : ~
	&H_{\Gamma, s}(\hat{\phi_{pre}}) = \hat{\phi_{post}} ~\wedge~
	env ~\vdash~ \hat{\phi_{pre}}\\
&\implies\\
	\exists \hat{\phi_{pre}} \in \gamma(\grad{\phi_{pre}}), \hat{\phi_{post}} \in \gamma(\grad{\phi_{post}}) : ~
	&\Gamma \hoare {\hat{\phi_{pre}}} {s} {\hat{\phi_{post}}} ~\wedge~
	env ~\vdash~ \hat{\phi_{pre}}\\
&\implies\\
	\exists \hat{\phi_{pre}} \in \gamma(\grad{\phi_{pre}}), \hat{\phi_{post}} \in \gamma(\grad{\phi_{post}}) : ~
	&\TappVER_{\Gamma, s, env}(\hat{\phi_{pre}}, \hat{\phi_{post}})
	\end{align*}
	
	Note that it implicitly ensures $\grad{\phi} \grad{\implies} \grad{\phi_{pre}} \grad{\implies} \goal(s)$ ($\hat{\phi}$ was simplified away earlier).
	However, in our setting we could simplify away the subtyping/implication-judgments that can be found in AGT:
	Since checking whether an environment has a certain type is naturally defined as a conservative approximation (to whichever type describes the environment in most detail), type-judgments can always be combined with subtyping-judgments (just making the approximation a little worse).
	
	Bottom line, instead of introducing evidence we end up with an additional premise $env \vdash \withqm{\goal(s)}$ which can easily be checked at runtime.
	% Note: optimization.
\end{description}

%Known:
%\begin{align*}
%\forall \grad{\phi}, \grad{f}(\grad{\phi}) &= \alpha(\overline{f}(\gamma(\grad{\phi}))) \\
%&\wedge\\
%\forall \grad{\phi}, \grad{g}(\grad{\phi}) &= \alpha(\overline{g}(\gamma(\grad{\phi}))) \\
%&\implies \\
%\forall \grad{\phi}, \grad{f}(\grad{g}(\grad{\phi})) &= \alpha(\overline{f}(\gamma(\alpha(\overline{g}(\gamma(\grad{\phi})))))) 
%\end{align*}

%Goal:
%\begin{align*}
%\forall \grad{\phi}, 
%\alpha(\overline{f}(\gamma(\alpha(\overline{g}(\gamma(\grad{\phi})))))) &= \alpha(\overline{f}(\overline{g}(\gamma(\grad{\phi}))))\\
%&\iff \\
%\forall \grad{\phi}, 
%\grad{f}(\grad{g}(\grad{\phi})) &= \grad{f \circ g}(\grad{\phi})\\
%&\iff \\
%\text{piecewise lifting of HSec} &= \text{GHSec}\\
%\end{align*}

%Holds (since $\gamma \circ \alpha$ is widening):
%\begin{align*}
%\forall \grad{\phi}, 
%\alpha(\overline{f}(\gamma(\alpha(\overline{g}(\gamma(\grad{\phi})))))) &\sqsupseteq \alpha(\overline{f}(\overline{g}(\gamma(\grad{\phi}))))\\
%\end{align*}

%Goal (solvable with $\dagger(f)$ but that is not the case for implication!):
%\begin{align*}
%\forall \grad{\phi}, 
%\forall \hat{\phi_1} \in \gamma(\alpha(\overline{g}(\gamma(\grad{\phi})))), 
%\withqm{f(\hat{\phi_1})} &\sqsubseteq 
%\sup \{~ \withqm{f(\hat{\phi})} ~|~ \hat{\phi} \in \overline{g}(\gamma(\grad{\phi})) ~\}\\
%&\iff \\
%\forall \grad{\phi}, 
%\sup \{~ \withqm{f(\hat{\phi})} ~|~ \hat{\phi} \in \gamma(\alpha(\overline{g}(\gamma(\grad{\phi})))) ~\} &\sqsubseteq 
%\sup \{~ \withqm{f(\hat{\phi})} ~|~ \hat{\phi} \in \overline{g}(\gamma(\grad{\phi})) ~\}\\
%&\iff \\
%\forall \grad{\phi}, 
%\alpha(\{~ f(\hat{\phi}) ~|~ \hat{\phi} \in \gamma(\alpha(\overline{g}(\gamma(\grad{\phi})))) ~\}) &\sqsubseteq
%\alpha(\{~ f(\hat{\phi}) ~|~ \hat{\phi} \in \overline{g}(\gamma(\grad{\phi})) ~\})\\
%&\iff \\
%\forall \grad{\phi}, 
%\alpha(\overline{f}(\gamma(\alpha(\overline{g}(\gamma(\grad{\phi})))))) &\sqsubseteq \alpha(\overline{f}(\overline{g}(\gamma(\grad{\phi}))))\\
%\end{align*}

\subsubsection{Alternative angle: evidence = interior}
Lemmas $\forall \grad{\phi}, \hat{\phi'}$:
\begin{align*}
\exists \hat{\phi}. 
&\hat{\phi} \in \gamma(\grad{\phi}) \wedge \hat{\phi'} \implies \hat{\phi}
\quad\quad
\iff
\quad\quad
\hat{\phi'} \in \gamma(\withqm{static(\grad{\phi})})\\
&\hat{\phi} \in \gamma(\grad{\phi}) \wedge \hat{\phi} \implies \hat{\phi'}
\quad\quad
\iff
\quad\quad
\hat{\phi} \in \gamma(\grad{\imp}(\hat{\phi'})(\grad{\phi}))\\
\end{align*}


Interior of implication:
\begin{align*}
\mathcal{I}_{\implies}(\grad{\phi_1}, \grad{\phi_2})
= \langle 
    &\alpha(\{~ \hat{\phi_1} \in \gamma(\grad{\phi_1}) ~|~ \exists \hat{\phi_2} \in \gamma(\grad{\phi_2}). \hat{\phi_1} \implies \hat{\phi_2} ~\}),
    &&\alpha(\{~ \hat{\phi_2} \in \gamma(\grad{\phi_2}) ~|~ \exists \hat{\phi_1} \in \gamma(\grad{\phi_1}). \hat{\phi_1} \implies \hat{\phi_2} ~\}) 
\rangle\\
= \langle 
    &\alpha(\{~ \hat{\phi_1} \in \gamma(\grad{\phi_1}) ~|~ \hat{\phi_1} \in \gamma(\withqm{static(\grad{\phi_2})}) ~\}),
    &&\grad{\phi_2} 
\rangle\\
= \langle 
    &\grad{\imp}(static(\grad{\phi_2}))(\grad{\phi_1}),
    &&\grad{\phi_2} 
\rangle\\
\end{align*}

Interior of consistent transitivity:
\begin{align*}
\Delta^{\implies}(\grad{\phi_1}, \grad{\phi_2}, \grad{\phi_3})
=~&\alpha^2(\{~ \langle \hat{\phi_1}, \hat{\phi_3} \rangle \in \gamma^2(\grad{\phi_1}, \grad{\phi_3}) ~|~ \exists \hat{\phi_2} \in \gamma(\grad{\phi_2}). \hat{\phi_1} \implies \hat{\phi_2} \wedge \hat{\phi_2} \implies \hat{\phi_3} ~\}) \\
= \langle 
&\alpha(\{~ \hat{\phi_1} \in \gamma(\grad{\phi_1}) ~|~ \exists \hat{\phi_3} \in \gamma(\grad{\phi_3}), \hat{\phi_2} \in \gamma(\grad{\phi_2}). \hat{\phi_1} \implies \hat{\phi_2} \wedge \hat{\phi_2} \implies \hat{\phi_3} ~\}),\\
&\alpha(\{~ \hat{\phi_3} \in \gamma(\grad{\phi_3}) ~|~ \exists \hat{\phi_1} \in \gamma(\grad{\phi_1}), \hat{\phi_2} \in \gamma(\grad{\phi_2}). \hat{\phi_1} \implies \hat{\phi_2} \wedge \hat{\phi_2} \implies \hat{\phi_3} ~\})
\rangle\\
= \langle 
&\alpha(\{~ \hat{\phi_1} \in \gamma(\grad{\phi_1}) ~|~ \exists \hat{\phi_2} \in \gamma(\grad{\phi_2}). \hat{\phi_1} \implies \hat{\phi_2} \wedge (\exists \hat{\phi_3} \in \gamma(\grad{\phi_3}). \hat{\phi_2} \implies \hat{\phi_3}) ~\}),\\
&\alpha(\{~ \hat{\phi_3} \in \gamma(\grad{\phi_3}) ~|~ \exists \hat{\phi_1} \in \gamma(\grad{\phi_1}), \hat{\phi_2}. \hat{\phi_1} \implies \hat{\phi_2} \wedge \hat{\phi_2} \in \gamma(\grad{\phi_2}) \wedge \hat{\phi_2} \implies \hat{\phi_3} ~\})
\rangle\\
= \langle 
&\alpha(\{~ \hat{\phi_1} \in \gamma(\grad{\phi_1}) ~|~ \exists \hat{\phi_2} \in \gamma(\grad{\phi_2}). \hat{\phi_1} \implies \hat{\phi_2} \wedge \hat{\phi_2} \in \gamma(\withqm{static(\grad{\phi_3})}) ~\}),\\
&\alpha(\{~ \hat{\phi_3} \in \gamma(\grad{\phi_3}) ~|~ \exists \hat{\phi_1} \in \gamma(\grad{\phi_1}), \hat{\phi_2}. \hat{\phi_1} \implies \hat{\phi_2} \wedge \hat{\phi_2} \in \gamma(\grad{\imp}(\hat{\phi_3})(\grad{\phi_2})) ~\})
\rangle\\
= \langle 
&\alpha(\{~ \hat{\phi_1} \in \gamma(\grad{\phi_1}) ~|~ \exists \hat{\phi_2} \in \gamma(\grad{\imp}(static(\grad{\phi_3}))(\grad{\phi_2})). \hat{\phi_1} \implies \hat{\phi_2} ~\}),\\
&\alpha(\{~ \hat{\phi_3} \in \gamma(\grad{\phi_3}) ~|~ \exists \hat{\phi_1} \in \gamma(\grad{\phi_1}). \hat{\phi_1} \in \gamma(\withqm{static(\grad{\imp}(\hat{\phi_3})(\grad{\phi_2}))}) ~\})
\rangle\\
= \langle 
&\alpha(\{~ \hat{\phi_1} \in \gamma(\grad{\phi_1}) ~|~ \hat{\phi_1} \in \gamma(\withqm{static(\grad{\imp}(static(\grad{\phi_3}))(\grad{\phi_2}))}) ~\}),\\
&\alpha(\{~ \hat{\phi_3} \in \gamma(\grad{\phi_3}) ~|~ \gamma(\grad{\imp}(static(\grad{\imp}(\hat{\phi_3})(\grad{\phi_2})))(\gamma(\grad{\phi_1}))) \neq \emptyset  ~\})
\rangle\\
= \langle 
&\alpha(\gamma(\grad{\imp}(static(\grad{\imp}(static(\grad{\phi_3}))(\grad{\phi_2})))(\grad{\phi_1}))), \\
&\grad{\phi_3}
\rangle\\
= \langle 
&\grad{\imp}(static(\grad{\imp}(static(\grad{\phi_3}))(\grad{\phi_2})))(\grad{\phi_1}), \\
&\grad{\phi_3}
\rangle\\
\end{align*}
         
Evidence combination (invariant: $\grad{\phi_{22}} \sqsubseteq \grad{\phi_{21}}$):
\begin{align*}
   &\langle \grad{\phi_1}, \grad{\phi_{21}} \rangle \circ^{\implies} \langle \grad{\phi_{22}}, \grad{\phi_3} \rangle \\
=~ &\Delta^{\implies}(\grad{\phi_1}, \grad{\phi_{21}} \sqcap \grad{\phi_{22}}, \grad{\phi_3}) \\
=~ &\Delta^{\implies}(\grad{\phi_1}, \grad{\phi_{22}}, \grad{\phi_3}) \\
=~ &
\langle 
\grad{\imp}(static(\grad{\imp}(static(\grad{\phi_3}))(\grad{\phi_{22}})))(\grad{\phi_1}),
\grad{\phi_3}
\rangle
\end{align*}
         
\subsection{Lifting implication}
Implication is the only predicate on pairs of $\phi$ occurring in our Hoare rules.\\

Looking at HAssert (the version with forwarding pre to post-condition) shows that the gradual lifting is not achieved by merely replacing the implication with gradual implication.
The gradual lifting potentially has a stronger postcondition than precondition due to filtering out of all concrete formulas that don't satisfy the implication (i.e. where the partial function HAssert is undefined).
TODO in thesis: Actually elaborate this in more detail (with example, etc.) AAAANNND show the alternative definition (that is actually correct but not ideal) that uses removal and re-addition of the asserted formula!\\

GHAssert could be defined using appropriate additional measures (e.g. manually fixing up the postcondition) but the problem can be tackled more elegantly by redesigning implication itself.\\

In general, whenever implication is used, the set of potential formulas is reduced. Without mirroring this reduction in the static system, evidence is required to make sure the reduction does not contradict assertions down the road.\\

We will create a partial function based on classical implication and give its gradual lifting.
The gradual lifting will by definition mirror reductions caused by the implication, restoring the simplicity of HAssert and especially GHAssert and removing(?) the need of evidence (TODO: evidence is now actually the return value!).\\

% The problem with arbitrary predicates (compared to partial functions) is that their lifting merely guarantees the possibility of succeeding at runtime, generating no further information about when it will succeed.
% As a result evidence is required to provide the necessary information at runtime.

\subsubsection{Implication as partial function $\imp : \phi \rightarrow \hat{\phi} \rightarrow \hat{\phi}$}
\begin{align*}
&\imp(\phi_a)(\hat{\phi}) = \hat{\phi}                   &&\text{if $\hat{\phi} \implies \phi_a$}\\
&\imp(\phi_a)(\hat{\phi}) \textit{~undefined}      &&\text{otherwise}\\
\end{align*}

\subsubsection{Gradual lifting $\grad{\imp} : \phi \rightarrow \grad{\phi} \rightarrow \grad{\phi}$}
\begin{align*}
&\grad{\imp}(\phi_a)(\grad{\phi}) 
  &&= \alpha(\overline{\imp(\phi_a)}(\gamma(\grad{\phi})))\\
& &&= \alpha(\{~ \imp(\phi_a)(\hat{\phi}) ~|~ \hat{\phi} \in \gamma(\grad{\phi}) ~\})\\
& &&= \alpha(\{~ \hat{\phi} ~|~ \hat{\phi} \in \gamma(\grad{\phi}) \wedge \hat{\phi} \implies \phi_a ~\})\\
& &&= \alpha(\{~ \hat{\phi} ~|~ \hat{\phi} \in \gamma(\grad{\phi}) \wedge \hat{\phi} \in \gamma(\withqm{\phi_a}) ~\})\\
& &&= \alpha(\gamma(\grad{\phi}) \cap \gamma(\withqm{\phi_a}))\\
\end{align*}

This definition turns out to be implementable trivially.

\newcommand{\norm}{\textrm{norm}}
\newcommand{\snorm}{\norm'}
\subsection{Gradual Normal Form}
TODO: make clear that this is specifically about GRADUAL formulas, i.e. ones containing $\qm$!!!

TODO: declare some appropriate naming conventions to distinguish

We cannot compare gradual formulas (in terms of inclusion or equality) by comparing their static parts:

TODO: example of equal gradual formulas but non-equal static parts\\

Fortunately, there exists a normal form $\norm(\withqm{\phi}) = \withqm{\snorm(\phi)}$ for any gradual formula $\withqm{\phi}$ that satisfies the following properties:
\begin{itemize}
	\item $\norm(\withqm{\phi}) = \withqm{\phi}$ (mandatory for any normal form)
	\item $\snorm(\phi)$ is well defined modulo equivalence, i.e. the normal form is unique modulo equivalence of the static part
	\item $\phi \implies \snorm(\phi)$
	\item $\snorm(\phi)$ contains no access-terms and therefore no elements of linear logic
	\item $\withqm{\phi_1} \sqsubseteq \withqm{\phi_2}  \quad\iff\quad  \snorm(\phi_1) \implies \snorm(\phi_2)$
\end{itemize} 

\subsubsection{Definition}
Recall that gradual formulas $\withqm{\phi_1}$ and $\withqm{\phi_2}$ are considered equal iff $\gamma(\withqm{\phi_1}) = \gamma(\withqm{\phi_1})$.
The normal form makes use of the fact that concretizations contain only self-framed formulas.

Lemma:
For any formula $\phi$ mentioning $\edot{$x$}{$f$}$:
$$\forall \hat{\phi} \in \gamma(\withqm{\phi}), \hat{\phi} \implies \phiAcc{$x$}{$f$}$$

In other words: Merely mentioning a field will make sure that the concretization contains appropriate framing.
This is a good starting point to justify removal of access-terms from the static part.
Note, however, that just dropping all access from the static part may not result in an equivalent gradual formula for two reasons:
\begin{description}
	\item[1. Mentioning]~\\
	Dropping $\phiAcc{$x$}{$f$}$ might result in $\edot{$x$}{$f$}$ not being mentioned in the formula anymore, so there would be no more reason for the access to be restored by concretization.
	
	\item[2. Aliasing]~\\
	In general there are different ways in which access to multiple fields can be restored (this is were linear logic plays in).
	Example: Dropping all access from $\phiCons{\phiCons{\phiAcc{a}{f}}{\phiAcc{b}{f}}}{\phiCons{\phiEq{a.f}{3}}{\phiEq{b.f}{x}}}$
	results in
	$\phiCons{\phiEq{a.f}{3}}{\phiEq{b.f}{x}}$
	which might be re-framed as
	$\phiCons{\phiCons{\phiAcc{a}{f}}{\phiEq{a}{b}}}{\phiCons{\phiEq{a.f}{3}}{\phiEq{a.f}{x}}}$.
	In other words, the possibility of aliasing may result in a variety of re-framed formulas that are not equivalent with the original one.
	% Elaborate in more detail why this is bad?
	% Also: this is where dominators play in... draw the line? How far?
\end{description}

Fortunately, we can prevent both problems from occurring by carefully preparing the static part before dropping all access, resulting in the following two-step approach:

\begin{description}
	\item[1. Enhancement]~\\
	Enrich the static part to counteract above problems, i.e. to enforce that access is restored exactly the right way.
	This is achieved by simply spelling out certain implications of the access-terms:
	\begin{description}
		\item [$\phiAcc{$x$}{$f$} \implies \phiEq{\edot{$x$}{$f$}}{\edot{$x$}{$f$}}$]~\\
		Access to a field implicitly guarantees that it actually evaluates to some (arbitrary) value.
		Note that $\phiEq{\edot{$x$}{$f$}}{\edot{$x$}{$f$}}$ is not a logical tautology (i.e. it is not implies by $\phiTrue$), since it indeed makes sure that $\edot{$x$}{$f$}$ evaluates, whereas $\phiTrue$ does not.
		The bottom line is that $\edot{$x$}{$f$}$ is being mentioned even after dropping $\phiAcc{$x$}{$f$}$, therefore solving the first problem. 
		\item [$\phiCons{\phiAcc{$x$}{$f$}}{\phiAcc{$y$}{$f$}} \implies \phiNeq{$x$}{$y$}$]~\\
		Having access to the same field of different expressions actively prevents those expressions to ever alias.
		Spelling out this restriction by adding the corresponding inequality also prevents re-framing in a way that relies on aliasing.
		The bottom line is that any valid re-framing must restore two distinct access-terms, therefore solving the second problem.
	\end{description}
	We enhance the non-linear part of our formula by spelling out above implications in every possible way, i.e. accounting for all (pairs of) access-terms.
	It is worth noting that this enhancement preserves equality of the formula as only terms are added that were implied by the original formula, anyway.
	
	\item[2. Delinearization]~\\
	All access-terms are dropped.
\end{description}



\subsubsection{Properties}
...prove properties postulated above.

equality (results directly from last prop.)

Intersection:
\begin{align*}
&\withqm{\phi_1} \sqcap \withqm{\phi_2} 
  && := \alpha(\gamma(\withqm{\phi_1}) \cap \gamma(\withqm{\phi_2})) \\
& &&  = \alpha(\gamma(\norm(\withqm{\phi_1})) \cap \gamma(\norm(\withqm{\phi_2}))) \\
& &&  = \alpha(\gamma(\withqm{\snorm(\phi_1)}) \cap \gamma(\withqm{\snorm(\phi_2)})) \\
& &&  = \alpha(\{~ \hat{\phi} ~|~ \hat{\phi} \implies \snorm(\phi_1) ~\} \cap \{~ \hat{\phi} ~|~ \hat{\phi} \implies \snorm(\phi_2) ~\}) \\
& &&  = \alpha(\{~ \hat{\phi} ~|~ \hat{\phi} \implies \snorm(\phi_1) \wedge \hat{\phi} \implies \snorm(\phi_2) ~\}) \\
& &&  = \alpha(\{~ \hat{\phi} ~|~ \hat{\phi} \implies \phiCons{$\snorm(\phi_1)$}{$\snorm(\phi_2)$} ~\}) \\
& &&  = \alpha(\gamma(\withqm{\phiCons{$\snorm(\phi_1)$}{$\snorm(\phi_2)$}})) \\
& &&  = \withqm{\phiCons{$\snorm(\phi_1)$}{$\snorm(\phi_2)$}} \\
\end{align*}

\subsubsection{Redefinition of gradual lifting}
\begin{align*}
&\grad{\imp}(\phi_a)(\grad{\phi}) 
  &&= \alpha(\gamma(\grad{\phi}) \cap \gamma(\withqm{\phi_a}))\\
&\text{is equivalent to}\\
&\grad{\imp}(\phi_a)(\phi) 
  &&= \imp(\phi_a)(\phi) 	\quad\quad\quad\text{(by definition)}\\
&\grad{\imp}(\phi_a)(\withqm{\phi}) 
%  &&= \alpha(\gamma(\withqm{\phi}) \cap \gamma(\withqm{\phi_a}))\\ &
  &&= \withqm{\phiCons{$\snorm(\phi)$}{$\snorm(\phi_a)$}} \\
\end{align*}


\subsection{Gradual Lifting}
\subsubsection{Self framing}
\begin{mathpar}
\inferrule* [Right=GSfrmNonGrad]
{A \sfrmphi \phi}
{A ~\grad{\sfrmphi}~ \phi}
\end{mathpar}

\begin{mathpar}
\inferrule* [Right=GSfrmGrad]
{~}
{A ~\grad{\sfrmphi}~ \withqm{\phi}}
\end{mathpar}

\subsubsection{Implication}
\begin{mathpar}
\inferrule* [Right=GImplNonGrad]
{\phi_1 \implies \phi_2}
{\phi_1 ~\grad{\implies}~ \grad{\phi_2}}
\end{mathpar}

\begin{mathpar}
\inferrule* [Right=GImplGrad]
{\hat{\phi_m} \implies \phi_2 \\
 \hat{\phi_m} \implies \phi_1}
{\withqm{\phi_1} ~\grad{\implies}~ \grad{\phi_2}}
\end{mathpar}


\textbf{Minimum runtime checks}: For $\grad{\phi_1} \grad{\implies} \grad{\phi_2}$ to hold at runtime, practically just $\phi_2$ needs to hold. So that would be a valid assertion to check. Yet, we know statically that $\phi_1$ holds, so we can remove everything from the runtime check that is implied by $\phi_1$.
So in a sense, we only need to check $\phi_2 \backslash \phi_1$ at runtime (the operator can be an approximation).


%Remark: Whether second argument is gradual or not seems to be irrelevant. Interestingly, all of our later uses will also pass non-gradual formulas as second argument. Maybe the natural lifting of this predicate should only lift on first argument in the first place?

$\hat{\phi_m}$ is evidence! \\


\textbf{Consistent transitivity}

While $\implies$ is transitive, $\grad{\implies}$ is generally not.

But maybe not even necessary with smarter hoare rules?

%\subsubsection{Free Variable}
%\begin{mathpar}
%\inferrule* [Right=GNotInFV]
%{x \not\in FV(\phi)}
%{x \not\in FV(\grad{\phi})}
%\end{mathpar}

\subsubsection{Equality}
\begin{mathpar}
\inferrule* [Right=GEqStatic]
{\phi_1 = \phi_2}
{\phi_1 \approx \phi_2}
\end{mathpar}

\begin{mathpar}
\inferrule* [Right=GEqGradual]
{
\text{at least one of $\grad{\phi_1}$ or $\grad{\phi_2}$ contains $?$}
\\\\
\grad{\phi_1} \grad{\implies} \grad{\phi_2} \\
\grad{\phi_2} \grad{\implies} \grad{\phi_1}
}
{\grad{\phi_1} \approx \grad{\phi_2}}
\end{mathpar}

\subsubsection{Append}
\begin{align*}
&\text{by definition:}\\
&\grad{\phi} ~\grad{*}~ \phi_p = \alpha(\gamma(\grad{\phi}) \overline{*} \phi_p)
&~\\\\
&\text{equivalent to:}\\
&\grad{\phi} ~\grad{*}~ \phi_p = \grad{\phi} * \phi_p
      && \text{if~} \forall \hat{\phi_1}, (\hat{\phi_1} \implies \phi * \phi_p) \implies 
                    \exists \hat{\phi_2}, (\hat{\phi_2} \implies \phi \wedge \hat{\phi_1} \implies \hat{\phi_2} * \phi_p) \\
&~
      && \text{if~} \forall \hat{\phi_1} \in \gamma(\grad{\phi} * \phi_p), 
                    \exists \hat{\phi_2} \in \gamma(\grad{\phi}), \hat{\phi_1} \implies \hat{\phi_2} * \phi_p \\
&\grad{\phi} ~\grad{*}~ \phi_p \textit{~undefined}
      && \text{otherwise}
\end{align*}
% (forall p'',(good p'' /\ phiImplies p'' (snd gp1 ++ p)) ->
% exists p' , good p'  /\ phiImplies p'  (snd gp1) /\ phiImplies p'' (p' ++ p))



\subsection{Theorems}
\subsubsection{Soundness of $\alpha$}
\begin{align*}
&\forall \overline{\phi} : \overline{\phi} \subseteq \gamma(\alpha(\overline{\phi}))
\end{align*}
\subsubsection{Optimality of $\alpha$}
\begin{align*}
&\forall \overline{\phi}, \grad{\phi} : \overline{\phi} \subseteq \gamma(\grad{\phi}) \implies  \gamma(\alpha(\overline{\phi}))\subseteq
\gamma(\grad{\phi}) 
\end{align*}

\section{Theorems}
\subsection{Invariant $invariant(H, \rho, A_d, \phi)$}

\subsubsection{Phi valid}
\begin{align*}
    \sfrmphi {\phi}
\end{align*}

\subsubsection{Phi holds}
\begin{align*}
    \evalphix {H} {\rho} {A_d} {\phi}
\end{align*}

\subsubsection{Types preserved}
\begin{align*}
    \forall e, T : \sType {\phi} {e} {T}& \\
    \implies \dType {H} {\rho} {e} {T}&
\end{align*}

\subsubsection{Heap consistent}
\begin{align*}
\forall o, C, \mu, f, T :&~ 
H(o) = (C, \mu) \\
\implies&~ 
\texttt{fieldType}(C,f) = T \\
\implies&~
\dType {H} {\rho} {\mu(f)} {T}
\end{align*}

\subsubsection{Heap not total}
\begin{align*}
\exists o_{min} :&\\
\forall o \ge o_{min} :&~ o \not \in \texttt{dom}(H) \\
\wedge&~ \forall f, (o, f) \not \in A
\end{align*}

\subsection{Soundness}
\subsubsection{Progress}
\begin{align*}
\forall~ ... &:~~ \hoare {\phi_1} {s'} {\phi_2} 
\\ &\implies invariant(H_1, \rho_1, A_1, \phi_1)
\\ &\implies \exists H_2, \rho_2, A_2 : (H_1, (\rho_1, A_1, s' ; \overline{s}) \cdot S)
							\rightarrow^* (H_2, (\rho_2, A_2, \overline{s}) \cdot S)
\end{align*}

\subsubsection{Preservation}
\begin{align*}
\forall~ ... &:~~ \hoare {\phi_1} {s'} {\phi_2} 
\\ &\implies invariant(H_1, \rho_1, A_1, \phi_1)
\\ &\implies (H_1, (\rho_1, A_1, s' ; \overline{s}) \cdot S)
  \rightarrow^* (H_2, (\rho_2, A_2, \overline{s}) \cdot S)
\\ &\implies invariant(H_2, \rho_2, A_2, \phi_2)
\end{align*}

\end{document}